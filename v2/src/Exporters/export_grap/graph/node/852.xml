{"properties":{"genre":"Article","timestamp":"2013-10-10T18:46:08Z","author":["Eyre-Walker, Adam","Stoletzki, Nina"],"title":"Data from: The assessment of science: the relative merits of post-publication review, the impact factor and the number of citations","host":"Eyre-Walker A, Stoletzki N (2013) The assessment of science: the relative merits of post-publication review, the impact factor and the number of citations. PLoS Biology 11(10): e1001675.","keywords":["Impact factor","quality of science","citations","research excellence framework","research assessment exercise","merit of science"],"description":"Background: The assessment of scientific publications is an integral part of the scientific process. Here we investigate three methods of assessing the merit of a scientific paper: subjective post-publication peer review, the number of citations gained by a paper and the impact factor of the journal in which the article was published. Methodology/principle findings: We investigate these methods using two datasets in which subjective post-publication assessments of scientific publications have been made by experts. We find that there are moderate, but statistically significant, correlations between assessor scores, when two assessors have rated the same paper, and between assessor score and the number of citations a paper accrues. However, we show that assessor score depends strongly on the journal in which the paper is published, and that assessors tend to over-rate papers published in journals with high impact factors. If we control for this bias, we find that the correlation between assessor scores and between assessor score and the number of citations is weak, suggesting that scientists have little ability to judge either the intrinsic merit of a paper or its likely impact. We also show that the number of citations a paper receives is an extremely error-prone measure of scientific merit. Finally, we argue that the impact factor is likely to be a poor measure of merit, since it depends on subjective assessment. Conclusions: We conclude that the three measures of scientific merit considered here are poor; in particular subjective assessments are an error-prone, biased and expensive method by which to assess merit. We argue that the impact factor may be the most satisfactory of the methods we have considered, since it is a form of pre-publication review. However, we emphasise that it is likely to be a very error-prone measure of merit that is qualitative, not quantitative.","constituent":["doi:10.5061/dryad.2h4j5/2","doi:10.5061/dryad.2h4j5/1"],"identifier_uri":"http://hdl.handle.net/10255/dryad.51937","oai":"oai:datadryad.org:10255/dryad.51937","isReferencedBy":["PMID:24115908","doi:10.1371/journal.pbio.1001675"],"node_type":"Record","node_source":"Dryad","doi":"doi:10.5061/dryad.2h4j5"}}